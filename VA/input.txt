## ðŸŽ¬ Vision Action (VA) Models

### 2025

- [2025] Steering Your Diffusion Policy with Latent Space Reinforcement Learning [[paper](https://arxiv.org/pdf/2506.15799)] [[project](https://diffusion-steering.github.io/)]
- [2025] [**ByteDance Seed**] Chain-of-Action: Trajectory Autoregressive Modeling for Robotic Manipulation [[paper](https://arxiv.org/pdf/2506.09990)] [[project](https://chain-of-action.github.io/)]
- [2025] [**RSS 25**] Unified Video Action Model [[paper](https://arxiv.org/pdf/2503.00200)] [[project](https://unified-video-action-model.github.io/)]
- [2025] Streaming Flow Policy: Simplifying diffusion/flow-matching policies by treating action trajectories as flow trajectories [[paper](https://arxiv.org/pdf/2505.21851)] [[project](https://siddancha.github.io/streaming-flow-policy/)]
- [2025] Modality-Composable Diffusion Policy via Inference-Time Distribution-level Composition [[paper](https://arxiv.org/pdf/2503.12466)] [[project](https://github.com/AndyCao1125/MCDP)]
- [2025] Adapt3R: Adaptive 3D Scene Representation for Domain Transfer in Imitation Learning [[paper](https://arxiv.org/pdf/2503.04877)] [[project](https://www.pair.toronto.edu/Adapt3R/)]
- [2025] BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities [[paper](https://arxiv.org/pdf/2503.05652)] [[project](https://behavior-robot-suite.github.io/)]
- [2025] [**RSS 25**] Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation [[paper](https://arxiv.org/pdf/2503.02881)] [[project](https://reactive-diffusion-policy.github.io/)]
- [2025] Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics [[paper](https://arxiv.org/pdf/2501.10100)]
- [2025] You Only Teach Once: Learn One-Shot Bimanual Robotic Manipulation from Video Demonstrations [[paper](https://arxiv.org/pdf/2501.14208)]
- [2025] ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills [[paper](https://arxiv.org/pdf/2502.01143)]
- [2025] VILP: Imitation Learning with Latent Video Planning [[paper](https://arxiv.org/pdf/2502.01784)]
- [2025] Learning the RoPEs: Better 2D and 3D Position Encodings with STRING [[paper](https://arxiv.org/pdf/2502.02562)]
- [2025] When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning [[paper](https://arxiv.org/pdf/2502.03270)]
- [2025] RoboGrasp: A Universal Grasping Policy for Robust Robotic Control [[paper](https://arxiv.org/pdf/2502.03072)]
- [2025] CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World [[paper](https://arxiv.org/pdf/2502.08449)]
- [2025] Learning to Group and Grasp Multiple Objects [[paper](https://arxiv.org/pdf/2502.08452)]
- [2025] Beyond Behavior Cloning: Robustness through Interactive Imitation and Contrastive Learning [[paper](https://arxiv.org/pdf/2502.07645)]
- [2025] COMBO-Grasp: Learning Constraint-Based Manipulation for Bimanual Occluded Grasping [[paper](https://arxiv.org/pdf/2502.08054)]
- [2025] DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References [[paper](https://arxiv.org/pdf/2502.09614)]
- [2025] S2-Diffusion: Generalizing from Instance-level to Category-level Skills in Robot Manipulation [[paper](https://arxiv.org/pdf/2502.09389)]
- [2025] MTDP: Modulated Transformer Diffusion Policy Model [[paper](https://arxiv.org/pdf/2502.09029)]
- [2025] FUNCTO: Function-Centric One-Shot Imitation Learning for Tool Manipulation [[paper](https://arxiv.org/pdf/2502.11744)]
- [2025] RHINO: Learning Real-Time Humanoid-Human-Object Interaction from Human Demonstrations [[paper](https://arxiv.org/pdf/2502.13134)]
- [2025] Responsive Noise-Relaying Diffusion Policy: Responsive and Efficient Visuomotor Control [[paper](https://arxiv.org/pdf/2502.12724)]
- [2025] Learning a High-quality Robotic Wiping Policy Using Systematic Reward Analysis and Visual-Language Model Based Curriculum [[paper](https://arxiv.org/pdf/2502.12599)]
- [2025] IMLE Policy: Fast and Sample Efficient Visuomotor Policy Learning via Implicit Maximum Likelihood Estimation [[paper](https://arxiv.org/pdf/2502.12371)]
- [2025] X-IL: Exploring the Design Space of Imitation Learning Policies [[paper](https://arxiv.org/pdf/2502.12330)]
- [2025] Towards Fusing Point Cloud and Visual Representations for Imitation Learning [[paper](https://arxiv.org/pdf/2502.12320)]
- [2025] Pick-and-place Manipulation Across Grippers Without Retraining: A Learning-optimization Diffusion Policy Approach [[paper](https://arxiv.org/pdf/2502.15613)]
- [2025] FACTR: Force-Attending Curriculum Training for Contact-Rich Policy Learning [[paper](https://arxiv.org/pdf/2502.17432)]
- [2025] DemoGen: Synthetic Demonstration Generation for Data-Efficient Visuomotor Policy Learning [[paper](https://arxiv.org/pdf/2502.16932)]
- [2025] Human2Robot: Learning Robot Actions from Paired Human-Robot Videos [[paper](https://arxiv.org/pdf/2502.16587)]
- [2025] AnyDexGrasp: General Dexterous Grasping for Different Hands with Human-level Learning Efficiency [[paper](https://arxiv.org/pdf/2502.16420)]
- [2025] COMPASS: Cross-embOdiment Mobility Policy via ResiduAl RL and Skill Synthesis [[paper](https://arxiv.org/pdf/2502.16372)]
- [2025] Retrieval Dexterity: Efficient Object Retrieval in Clutters with Dexterous Hand [[paper](https://arxiv.org/pdf/2502.18423)]
- [2025] From planning to policy: distilling Skill-RRT for long-horizon prehensile and non-prehensile manipulation [[paper](https://arxiv.org/pdf/2502.18015)]
- [2025] FetchBot: Object Fetching in Cluttered Shelves via Zero-Shot Sim2Real [[paper](https://arxiv.org/pdf/2502.17894)]
- [2025] Point Policy: Unifying Observations and Actions with Key Points for Robot Manipulation [[paper](https://arxiv.org/pdf/2502.20391)] [[project](https://www.pi.website/research/hirobot)]
- [2025] FuseGrasp: Radar-Camera Fusion for Robotic Grasping of Transparent Objects [[paper](https://arxiv.org/pdf/2502.20037)]
- [2025] Sensor-Invariant Tactile Representation [[paper](https://arxiv.org/pdf/2502.19638)]
- [2025] Generalist World Model Pre-Training for Efficient Reinforcement Learning [[paper](https://arxiv.org/pdf/2502.19544)]
- [2025] ProDapt: Proprioceptive Adaptation using Long-term Memory Diffusion [[paper](https://arxiv.org/pdf/2503.00193)] [[project](https://github.com/Federico-PizarroBejarano/prodapt)]
- [2025] Falcon: Fast Visuomotor Policies via Partial Denoising [[paper](https://arxiv.org/pdf/2503.00339)]
- [2025] HGDiffuser: Efficient Task-Oriented Grasp Generation via Human-Guided Grasp Diffusion Models [[paper](https://arxiv.org/pdf/2503.00508)] [[project](https://sites.google.com/view/hgdiffuser)]
- [2025] SHADOW: Leveraging Segmentation Masks for Cross-Embodiment Policy Transfer [[paper](https://arxiv.org/pdf/2503.00774)] [[project](https://shadow-cross-embodiment.github.io/)]
- [2025] Phantom: Training Robots Without Robots Using Only Human Videos [[paper](https://arxiv.org/pdf/2503.00779)] [[project](https://phantom-human-videos.github.io/)]
- [2025] General Force Sensation for Tactile Robot [[paper](https://arxiv.org/pdf/2503.01058)]
- [2025] Action Tokenizer Matters in In-Context Imitation Learning [[paper](https://arxiv.org/pdf/2503.01206)]
- [2025] AVR: Active Vision-Driven Robotic Precision Manipulation with Viewpoint and Focal Length Optimization [[paper](https://arxiv.org/pdf/2503.01439)] [[project](https://avr-robot.github.io/)]
- [2025] FRMD: Fast Robot Motion Diffusion with Consistency-Distilled Movement Primitives for Smooth Action Generation [[paper](https://arxiv.org/pdf/2503.02048)]
- [2025] Variable-Friction In-Hand Manipulation for Arbitrary Objects via Diffusion-Based Imitation Learning [[paper](https://arxiv.org/pdf/2503.02738)] [[project](https://sites.google.com/view/vf-ihm-il/home)]
- [2025] Learning Dexterous In-Hand Manipulation with Multifingered Hands via Visuomotor Diffusion [[paper](https://arxiv.org/pdf/2503.02587)] [[project](https://dex-manip.github.io/)]
- [2025] RGBSQGrasp: Inferring Local Superquadric Primitives from Single RGB Image for Graspability-Aware Bin Picking [[paper](https://arxiv.org/pdf/2503.02387)] [[project](https://ilikesukiyaki.github.io/RGBSQGrasp/)]
- [2025] ArticuBot: Learning Universal Articulated Object Manipulation Policy via Large Scale Simulation [[paper](https://arxiv.org/pdf/2503.03045)] [[project](https://articubot.github.io/)]
- [2025] SRSA: Skill Retrieval and Adaptation for Robotic Assembly Tasks [[paper](https://arxiv.org/pdf/2503.04538)] [[project](https://srsa2024.github.io/)]
- [2025] GAGrasp: Geometric Algebra Diffusion for Dexterous Grasping [[paper](https://arxiv.org/pdf/2503.04123)] [[project](https://gagrasp.github.io/)]
- [2025] OPG-Policy: Occluded Push-Grasp Policy Learning with Amodal Segmentation [[paper](https://arxiv.org/pdf/2503.04089)]
- [2025] RA-DP: Rapid Adaptive Diffusion Policy for Training-Free High-frequency Robotics Replanning [[paper](https://arxiv.org/pdf/2503.04051)]
- [2025] Robotic Compliant Object Prying Using Diffusion Policy Guided by Vision and Force Observations [[paper](https://arxiv.org/pdf/2503.03998)] [[project](https://rros-lab.github.io/diffusion-with-force.github.io/)]
- [2025] CoinRobot: Generalized End-to-end Robotic Learning for Physical Intelligence [[paper](https://arxiv.org/pdf/2503.05316)]
- [2025] Persistent Object Gaussian Splat (POGS) for Tracking Human and Robot Manipulation of Irregularly Shaped Objects [[paper](https://arxiv.org/pdf/2503.05189)] [[project](https://berkeleyautomation.github.io/POGS/)]
- [2025] How to Train Your Robots? The Impact of Demonstration Modality on Imitation Learning [[paper](https://arxiv.org/pdf/2503.07017)]
- [2025] One-Shot Dual-Arm Imitation Learning [[paper](https://arxiv.org/pdf/2503.06831)] [[project](https://www.robot-learning.uk/one-shot-dual-arm)]
- [2025] GAT-Grasp: Gesture-Driven Affordance Transfer for Task-Aware Robotic Grasping [[paper](https://arxiv.org/pdf/2503.06227)]
- [2025] Enhanced View Planning for Robotic Harvesting: Tackling Occlusions with Imitation Learning [[paper](https://arxiv.org/pdf/2503.10334)]
- [2025] ES-Parkour: Advanced Robot Parkour with Bio-inspired Event Camera and Spiking Neural Network [[paper](https://arxiv.org/pdf/2503.09985)]
- [2025] NIL: No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models [[paper](https://arxiv.org/pdf/2503.10626)]
- [2025] World Modeling Makes a Better Planner: Dual Preference Optimization for Embodied Task Planning [[paper](https://arxiv.org/pdf/2503.10480)]
- [2025] RILe: Reinforced Imitation Learning [[paper](https://arxiv.org/pdf/2406.08472)]
- [2025] HumanoidPano: Hybrid Spherical Panoramic-LiDAR Cross-Modal Perception for Humanoid Robots [[paper](https://arxiv.org/abs/2503.09010)]
- [2025] Distillation-PPO: A Novel Two-Stage Reinforcement Learning Framework for Humanoid Robot Perceptive Locomotion [[paper](https://arxiv.org/abs/2503.08299)]
- [2025] Trinity: A Modular Humanoid Robot AI System [[paper](https://arxiv.org/abs/2503.08338)]
- [2025] LiPS: Large-Scale Humanoid Robot Reinforcement Learning with Parallel-Series Structures [[paper](https://arxiv.org/abs/2503.08349)]
- [2025] Elastic Motion Policy: An Adaptive Dynamical System for Robust and Efficient One-Shot Imitation Learning [[paper](https://arxiv.org/pdf/2503.08029)] [[project](https://elastic-motion-policy.github.io/EMP/)]
- [2025] Learning Gentle Grasping Using Vision, Sound, and Touch [[paper](https://arxiv.org/pdf/2503.07926)] [[project](https://lasr.org/research/gentle-grasping)]
- [2025] RoboCopilot: Human-in-the-loop Interactive Imitation Learning for Robot Manipulation [[paper](https://arxiv.org/pdf/2503.07771)]
- [2025] Rethinking Bimanual Robotic Manipulation: Learning with Decoupled Interaction Framework [[paper](https://arxiv.org/pdf/2503.09186)]
- [2025] MoE-Loco: Mixture of Experts for Multitask Locomotion [[paper](https://arxiv.org/pdf/2503.08564)] [[project](https://moe-loco.github.io/)]
- [2025] Humanoid Policy ~ Human Policy [[paper](https://arxiv.org/pdf/2503.13441)] [[project](https://human-as-robot.github.io/)]
- [2025] Dense Policy: Bidirectional Autoregressive Learning of Actions [[paper](https://arxiv.org/pdf/2503.13217)] [[project](https://selen-suyue.github.io/DspNet/)]
- [2025] Learning to Play Piano in the Real World [[paper](https://arxiv.org/pdf/2503.15481)] [[project](https://lasr.org/research/learning-to-play-piano)]
- [2025] CCDP: Composition of Conditional Diffusion Policies with Guided Sampling [[paper](https://arxiv.org/pdf/2503.15386)] [[project](https://hri-eu.github.io/ccdp/)]
- [2025] DyWA: Dynamics-adaptive World Action Model for Generalizable Non-prehensile Manipulation [[paper](https://arxiv.org/pdf/2503.16806)] [[project](https://pku-epic.github.io/DyWA/)]
- [2025] AdaWorld: Learning Adaptable World Models with Latent Actions [[paper](https://arxiv.org/pdf/2503.18938)] [[project](https://adaptable-world-model.github.io/)]
- [2025] Visuo-Tactile Object Pose Estimation for a Multi-Finger Robot Hand with Low-Resolution In-Hand Tactile Sensing [[paper](https://arxiv.org/pdf/2503.19893)]
- [2025] Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels [[paper](https://arxiv.org/pdf/2503.22634)]
- [2025] ManipTrans: Efficient Dexterous Bimanual Manipulation Transfer via Residual Learning [[paper](https://arxiv.org/pdf/2503.21860)] [[project](https://maniptrans.github.io/)]
- [2025] Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation [[paper](https://arxiv.org/pdf/2503.24361)] [[project](https://co-training.github.io/)]
- [2025] HACTS: a Human-As-Copilot Teleoperation System for Robot Learning [[paper](https://arxiv.org/pdf/2503.24070)]
- [2025] ZeroMimic: Distilling Robotic Manipulation Skills from Web Videos [[paper](https://arxiv.org/pdf/2503.23877)] [[project](https://zeromimic.github.io/)]
- [2025] Learning Coordinated Bimanual Manipulation Policies using State Diffusion and Inverse Dynamics Models [[paper](https://arxiv.org/pdf/2503.23271)]
- [2025] Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets [[paper](https://arxiv.org/pdf/2504.02792)] [[project](https://weirdlabuw.github.io/uwm/)]
- [2025] RoboAct-CLIP: Video-Driven Pre-training of Atomic Action Understanding for Robotics [[paper](https://arxiv.org/pdf/2504.02069)]
- [2025] Slot-Level Robotic Placement via Visual Imitation from Single Human Video [[paper](https://arxiv.org/pdf/2504.01959)] [[project](https://ddshan.github.io/slerp/)]
- [2025] Robust Dexterous Grasping of General Objects from Single-view Perception [[paper](https://arxiv.org/pdf/2504.05287)] [[project](https://zdchan.github.io/Robust_DexGrasp/)]
- [2025] Two by Two: Learning Multi-Task Pairwise Objects Assembly for Generalizable Robot Manipulation [[paper](https://arxiv.org/pdf/2504.06961)] [[project](https://tea-lab.github.io/TwoByTwo/)]
- [2025] ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping [[paper](https://arxiv.org/pdf/2504.10857)] [[project](https://sh8.io/#/zerograsp)]
- [2025] Novel Demonstration Generation with Gaussian Splatting Enables Robust One-Shot Manipulation [[paper](https://arxiv.org/pdf/2504.13175)] [[project](https://yangsizhe.github.io/robosplat/)]
- [2025] Grasping Deformable Objects via Reinforcement Learning with Cross-Modal Attention to Visuo-Tactile Inputs [[paper](https://arxiv.org/pdf/2504.15595)]
- [2025] Few-Shot Vision-Language Action-Incremental Policy Learning [[paper](https://arxiv.org/pdf/2504.15517)] [[project](https://github.com/codeshop715/FSAIL)]
- [2025] Latent Diffusion Planning for Imitation Learning [[paper](https://arxiv.org/pdf/2504.16925)] [[project](https://amberxie88.github.io/ldp/)]
- [2025] Physically Consistent Humanoid Loco-Manipulation using Latent Diffusion Models [[paper](https://arxiv.org/pdf/2504.16843)]
- [2025] PRISM-DP: Spatial Pose-based Observations for Diffusion-Policies via Segmentation, Mesh Generation, and Pose Tracking [[paper](https://arxiv.org/pdf/2504.20359)]
- [2025] Rethinking Latent Representations in Behavior Cloning: An Information Bottleneck Approach for Robot Manipulation [[paper](https://arxiv.org/pdf/2502.02853)] [[project](https://baishuanghao.github.io/BC-IB.github.io/)]
- [2025] Predictive Inverse Dynamics Models are Scalable Learners for Robotic Manipulation [[paper](https://arxiv.org/pdf/2412.15109)] [[project](https://nimolty.github.io/Seer/)]
- [2025] Fast Flow-based Visuomotor Policies via Conditional Optimal Transport Couplings [[paper](https://arxiv.org/pdf/2505.01179)] [[project](https://ansocho.github.io/cot-policy/)]
- [2025] KineDex: Learning Tactile-Informed Visuomotor Policies via Kinesthetic Teaching for Dexterous Manipulation [[paper](https://arxiv.org/pdf/2505.01974)] [[project](https://dinomini00.github.io/KineDex/)]
- [2025] CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations [[paper](https://arxiv.org/pdf/2505.04999)] [[project](https://clamrobot.github.io/)]
- [2025] H3DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning [[paper](https://arxiv.org/pdf/2505.07819)] [[project](https://lyy-iiis.github.io/h3dp/)]
- [2025] UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations [[paper](https://arxiv.org/pdf/2505.08787)] [[project](https://kimhanjung.github.io/UniSkill/)]
- [2025] Learning Long-Context Diffusion Policies via Past-Token Prediction [[paper](https://arxiv.org/pdf/2505.09561)] [[project](https://long-context-dp.github.io/)]
- [2025] DataMIL: Selecting Data for Robot Imitation Learning with Datamodels [[paper](https://arxiv.org/pdf/2505.09603)] [[project](https://robin-lab.cs.utexas.edu/datamodels4imitation/)]
- [2025] [**ICLR 25**] Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning [[paper](https://arxiv.org/pdf/2412.12953)] [[project](https://mbreuss.github.io/MoDE_Diffusion_Policy/)]
- [2025] IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning [[paper](https://arxiv.org/pdf/2505.10442)] [[project](https://github.com/ucd-dare/IN-RIL)]
- [2025] NVSPolicy: Adaptive Novel-View Synthesis for Generalizable Language-Conditioned Policy Learning [[paper](https://arxiv.org/pdf/2505.10359)]
- [2025] EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation [[paper](https://arxiv.org/pdf/2505.10105)]
- [2025] FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation [[paper](https://arxiv.org/pdf/2505.10075)] [[project](https://sharinka0715.github.io/FlowDreamer/)]
- [2025] Conditioning Matters: Training Diffusion Policies is Faster Than You Think [[paper](https://arxiv.org/pdf/2505.11123)]
- [2025] H2R: A Human-to-Robot Data Augmentation for Robot Pre-training from Videos [[paper](https://arxiv.org/pdf/2505.11920)]
- [2025] GLOVER++: Unleashing the Potential of Affordance Learning from Human Behaviors for Robotic Manipulation [[paper](https://arxiv.org/pdf/2505.11865)] [[project](https://teleema.github.io/projects/GLOVER++/)]
- [2025] Zero-Shot Visual Generalization in Robot Manipulation [[paper](https://arxiv.org/pdf/2505.11719)] [[project](https://sites.google.com/view/vis-gen-robotics/home)]
- [2025] Object-Centric Representations Improve Policy Generalization in Robot Manipulation [[paper](https://arxiv.org/pdf/2505.11563)]
- [2025] LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation [[paper](https://arxiv.org/pdf/2505.11528)]
- [2025] GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation [[paper](https://arxiv.org/pdf/2505.13441)] [[project](https://abhaybd.github.io/GraspMolmo/)]
- [2025] A Practical Guide for Incorporating Symmetry in Diffusion Policy [[paper](https://arxiv.org/pdf/2505.13431)]
- [2025] Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation [[paper](https://arxiv.org/pdf/2505.13982)] [[project](https://adaptac-dex.github.io/)]
- [2025] EquAct: An SE(3)-Equivariant Multi-Task Transformer for Open-Loop Robotic Manipulation [[paper](https://arxiv.org/pdf/2505.21351)]
- [2025] Spatial RoboGrasp: Generalized Robotic Grasping Control Policy [[paper](https://arxiv.org/pdf/2505.20814)]
- [2025] Learning Generalizable Robot Policy with Human Demonstration Video as a Prompt [[paper](https://arxiv.org/pdf/2505.20795)]
- [2025] [**AAAI 25**] FlowPolicy: Enabling Fast and Robust 3D Flow-Based Policy via Consistency Flow Matching for Robot Manipulation [[paper](https://arxiv.org/abs/2412.04987)] [[project](https://github.com/zql-kk/FlowPolicy)]
- [2025] Object-centric 3D Motion Field for Robot Learning from Human Videos [[paper](https://arxiv.org/pdf/2506.04227)] [[project](https://zhaohengyin.github.io/3DMF/)]
- [2025] Evaluating Robot Policies in a World Model [[paper](https://arxiv.org/pdf/2506.00613)] [[project](https://world-model-eval.github.io/)]
- [2025] 3DFlowAction: Learning Cross-Embodiment Manipulation from 3D Flow World Model [[paper](https://arxiv.org/pdf/2506.06199)] [[project](https://github.com/Hoyyyaard/3DFlowAction/)]
- [2025] SpikePingpong: High-Frequency Spike Vision-based Robot Learning for Precise Striking in Table Tennis Game [[paper](https://arxiv.org/pdf/2506.06690)]
- [2025] SAIL: Faster-than-Demonstration Execution of Imitation Learning Policies [[paper](https://arxiv.org/pdf/2506.11948)] [[project](https://nadunranawaka1.github.io/sail-policy/)]
- [2025] Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation [[paper](https://arxiv.org/pdf/2506.11261)] [[project](https://cshizhe.github.io/projects/robot_gondola.html)]
- [2025] Touch begins where vision ends: Generalizable policies for contact-rich manipulation [[paper](https://arxiv.org/pdf/2506.13762)] [[project](https://vitalprecise.github.io/)]
- [2025] AMPLIFY: Actionless Motion Priors for Robot Learning from Videos [[paper](https://arxiv.org/pdf/2506.14198)] [[project](https://amplify-robotics.github.io/)]
- [2025] GAF: Gaussian Action Field as a Dynamic World Model for Robotic Manipulation [[paper](https://arxiv.org/pdf/2506.14135)]
- [2025] Tactile Beyond Pixels: Multisensory Touch Representations for Robot Manipulation [[paper](https://arxiv.org/pdf/2506.14754)]
- [2025] Latent Action Diffusion for Cross-Embodiment Manipulation [[paper](https://arxiv.org/pdf/2506.14608)] [[project](https://mimicrobotics.github.io/lad/)]
- [2025] Vision in Action: Learning Active Perception from Human Demonstrations [[paper](https://arxiv.org/pdf/2506.15666)] [[project](https://vision-in-action.github.io/)]
- [2025] [**IROS 25**] Robust Instant Policy: Leveraging Studentâ€™s t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation [[paper](https://arxiv.org/pdf/2506.15157)] [[project](https://sites.google.com/view/robustinstantpolicy)]
- [2025] [**RSS 25**] Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation [[paper](https://arxiv.org/pdf/2506.17198)] [[project](https://jianglongye.com/dex1b/)]
- [2025] DemoDiffusion: One-Shot Human Imitation using pre-trained Diffusion Policy [[paper](https://arxiv.org/pdf/2506.20668)] [[project](https://demodiffusion.github.io/)]
- [2025] World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation [[paper](https://arxiv.org/pdf/2506.23919)] [[project](https://world4omni.github.io/)]
- [2025] ViTacFormer: Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation [[paper](https://arxiv.org/pdf/2506.15953)] [[project](https://github.com/RoboVerseOrg/ViTacFormer)]

### 2024

[](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln#2024-2)

- [2024] Learning Robotic Manipulation Policies from Point Clouds with Conditional Flow Matching [[paper](https://arxiv.org/pdf/2409.07343)]
- [2024] Point Cloud Matters: Rethinking the Impact of Different Observation Spaces on Robot Learning [[paper](https://arxiv.org/abs/2402.02500)]
- [2024] [**RSS 25**] 3D Diffusion Policy: Generalizable Visuomotor Policy Learning via Simple 3D Representations [[paper](https://arxiv.org/pdf/2403.03954)]
- [2024] Sparse diffusion policy: A sparse, reusable, and flexible policy for robot learning [[paper](https://arxiv.org/pdf/2407.01531)]
- [2024] ManiCM: Real-time 3D Diffusion Policy via Consistency Model for Robotic Manipulation [[paper](https://arxiv.org/pdf/2406.01586)]
- [2024] 3d diffuser actor: Policy diffusion with 3d scene representations [[paper](https://arxiv.org/pdf/2402.10885)]
- [2024] [**ICLR 25**] Diffusion Policy Policy Optimization [[paper](https://arxiv.org/pdf/2409.00588)]
- [2024] Language-Guided Object-Centric Diffusion Policy for Collision-Aware Robotic Manipulation [[paper](https://arxiv.org/pdf/2407.00451)]
- [2024] EquiBot: SIM(3)-Equivariant Diffusion Policy for Generalizable and Data Efficient Learning [[paper](https://arxiv.org/pdf/2407.01479)]
- [2024] Equivariant Diffusion Policy [[paper](https://arxiv.org/pdf/2407.01812)]
- [2024] [**IROS 25**] Mamba Policy: Towards Efficient 3D Diffusion Policy with Hybrid Selective State Models [[paper](https://arxiv.org/pdf/2409.07163)]
- [2024] Generalizable Humanoid Manipulation with Improved 3D Diffusion Policies [[paper](https://arxiv.org/pdf/2410.10803)]
- [2024] Motion Before Action: Diffusing Object Motion as Manipulation Condition [[paper](https://arxiv.org/pdf/2411.09658)]
- [2024] One-Step Diffusion Policy: Fast Visuomotor Policies via Diffusion Distillation [[paper](https://arxiv.org/pdf/2410.21257)]
- [2024] Consistency policy: Accelerated visuomotor policies via consistency distillation [[paper](https://arxiv.org/pdf/2405.07503)]
- [2024] SPOT: SE(3) Pose Trajectory Diffusion for Object-Centric Manipulation [[paper](https://arxiv.org/pdf/2411.00965)]
- [2024] Few-Shot Task Learning through Inverse Generative Modeling [[paper](https://arxiv.org/pdf/2411.04987)]
- [2024] G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation [[paper](https://arxiv.org/pdf/2411.18369)]
- [2024] Towards Synergistic, Generalized, and Efficient Dual-System for Robotic Manipulation [[paper](https://arxiv.org/pdf/2410.08001)]
- [2024] Diffusion Policy Attacker: Crafting Adversarial Attacks for Diffusion-based Policies [[paper](https://arxiv.org/pdf/2405.19424)]
- [2024] Imagination Policy: Using Generative Point Cloud Models for Learning Manipulation Policies [[paper](https://arxiv.org/pdf/2406.11740)]
- [2024] Equivariant diffusion policy [[paper](https://arxiv.org/pdf/2407.01812)]
- [2024] Scaling diffusion policy in transformer to 1 billion parameters for robotic manipulation [[paper](https://arxiv.org/pdf/2409.14411)]
- [2024] Data Scaling Laws in Imitation Learning for Robotic Manipulation [[paper](https://arxiv.org/pdf/2410.18647)]
- [2024] Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Ma_Hierarchical_Diffusion_Policy_for_Kinematics-Aware_Multi-Task_Robotic_Manipulation_CVPR_2024_paper.pdf)]
- [2024] Equivariant diffusion policy [[paper](https://arxiv.org/pdf/2407.01812)]
- [2024] Learning universal policies via text-guided video generation [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/1d5b9233ad716a43be5c0d3023cb82d0-Paper-Conference.pdf)]
- [2024] Crossway Diffusion: Improving Diffusion-based Visuomotor Policy via Self-supervised Learning [[paper](https://arxiv.org/pdf/2307.01849)]
- [2024] 3D Diffuser Actor: Policy Diffusion with 3D Scene Representations [[paper](https://arxiv.org/pdf/2402.10885)]
- [2024] Act3D: 3D Feature Field Transformers for Multi-Task Robotic Manipulation [[paper](https://arxiv.org/pdf/2306.17817)]
- [2024] GenDP: 3D Semantic Fields for Category-Level Generalizable Diffusion Policy [[paper](https://arxiv.org/pdf/2410.17488)]
- [2024] Lift3D Foundation Policy: Lifting 2D Large-Scale Pretrained Models for Robust 3D Robotic Manipulation [[paper](https://arxiv.org/pdf/2411.18623)]
- [2024] Prediction with Action: Visual Policy Learning via Joint Denoising Process [[paper](https://arxiv.org/pdf/2411.18179)]
- [2024] Video Prediction Policy: A Generalist Robot Policy with Predictive Visual Representations [[paper](https://arxiv.org/pdf/2412.14803)]
- [2024] Bidirectional Decoding: Improving Action Chunking via Closed-Loop Resampling [[paper](https://arxiv.org/pdf/2408.17355)]
- [2024] Streaming Diffusion Policy: Fast Policy Synthesis with Variable Noise Diffusion Models [[paper](https://arxiv.org/pdf/2406.04806)]
- [2024] CARP: Visuomotor Policy Learning via Coarse-to-Fine Autoregressive Prediction [[paper](https://arxiv.org/pdf/2412.06782)]
- [2024] In-Context Imitation Learning via Next-Token Prediction [[paper](https://arxiv.org/pdf/2408.15980)] [[project](https://icrt.dev/)]
- [2024] Learning Diffusion Policies from Demonstrations For Compliant Contact-rich Manipulation [[paper](https://arxiv.org/pdf/2410.19235)]

### 2023

[](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln#2023-2)

- [2023] Diffusion policy: Visuomotor policy learning via action diffusion [[paper](https://arxiv.org/pdf/2303.04137)]
- [2023] Exploring Visual Pre-training for Robot Manipulation: Datasets, Models and Methods [[paper](https://arxiv.org/pdf/2308.03620)]